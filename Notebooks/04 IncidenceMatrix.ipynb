{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bcc6f1d",
   "metadata": {},
   "source": [
    "# Búsqueda booleana por matriz de incidencia\n",
    "\n",
    "La matriz de incidencia de términos documentos indexa cada documento por medio de los términos. Así, se pueden hacer búsquedas booleanas (con operadores AND, OR y NOT) que nos permitan recuperar los documentos que respondan a las consultas booleanas. \n",
    "\n",
    "Aquí presentamos una versión simple para crear un modelo de búsqueda booleana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9212a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from re import compile\n",
    "from collections import defaultdict\n",
    "from itertools import chain, combinations\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248f1de",
   "metadata": {},
   "source": [
    "### Operadores booleanos\n",
    "\n",
    "Definimos los operadores booleanos que responden a operaciones lógicas tomando en cuenta las relaciones $True =1$ y $False = 0$. El operador NOT es un operador unitario y el operador AND y OR son binarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e4e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(x,y):\n",
    "    \"\"\"\n",
    "    Función booleana AND\n",
    "    \"\"\"\n",
    "    if x == 1 and y == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def NOT(x):\n",
    "    \"\"\"\n",
    "    Función booleana NOT\n",
    "    \"\"\"\n",
    "    if x == 1:\n",
    "        return 0\n",
    "    elif x == 0:\n",
    "        return 1\n",
    "    \n",
    "def OR(x,y):\n",
    "    \"\"\"\n",
    "    Función booleana OR\n",
    "    \"\"\"\n",
    "    if x == 0 and y == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef292571",
   "metadata": {},
   "source": [
    "### Tokenización\n",
    "\n",
    "Para poder trabajar con una colección de documentos, debemos obtener los términos tokenizándoles (e incluso aplicando stemming o lematización). Aquí definimos una función muy simple de tokenización que:\n",
    "\n",
    "* Limpia el texto eliminando caracteres no alfanuméricos.\n",
    "* Separa los tokens por los espacios en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef4fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = compile('[-_{}(),;:\"#\\/.¡!¿?·]')\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Función de tokenización.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    text : str\n",
    "        Cadena de texto que se tokenizará\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tokens : list\n",
    "        Lista de tokens\n",
    "    \"\"\"\n",
    "    #Pasa a minúsculas\n",
    "    lower_text = text.strip().lower()\n",
    "    #Elimina símbolos no alfanuméricos\n",
    "    alphanumeric = regex.sub('', lower_text)\n",
    "    #Obtiene tokens por espacios en blanco\n",
    "    tokens = alphanumeric.split()\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8f8ee",
   "metadata": {},
   "source": [
    "## Modelo de búsqueda booleana\n",
    "\n",
    "Construimos entonces una clase de un modelo de búsqueda booleana a partir de una colección de documentos. Este modelo guardará los términos y los documentos de la colección. Nos enfocamos en las siguientes funciones:\n",
    "\n",
    "* Función de creación de matriz de incidencia: crea la matriz de incidencia para indexar los documentos a partir de términos. Toma en cuenta una función de lectura de los documentos (get_documents()).\n",
    "* Función de representación de términos (vectorize()): Recupera el vector booleano de un término a patir de la matriz de incidencia.\n",
    "* Funciones de búsqueda booleana (searchAND(), searchOR() y searchNOT()): Recuperan los documentos que responden a las búsquedas booleanas entre términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dac3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanRetrieval(object):\n",
    "    \"\"\"\n",
    "    Clase para crear modelo de recuperación booleana sobre una colección \n",
    "    de documentos.\n",
    "    \n",
    "    docs_idx : dict\n",
    "        Dictionario que guarda los documentos y sus índices\n",
    "    terms : list\n",
    "        Lista de términos\n",
    "    documentos : list\n",
    "        Lista de documentos\n",
    "    collection : dict\n",
    "        Diccionario de índices de documentos y su lista de tokens\n",
    "    incidence_matriz : array\n",
    "        Matriz de incidencia término documento\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.docs_idx = {}\n",
    "        self.terms = []\n",
    "        self.documents = []\n",
    "        self.collection = {}\n",
    "        self.incidence_matrix = None \n",
    "    \n",
    "    def get_documents(self,directory):\n",
    "        \"\"\"\n",
    "        Función para obtener la colección de documentos a partir de un directorio con archivos.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        directory : str\n",
    "            Directorio donde se encuentran guardados los documentos\n",
    "        \"\"\"\n",
    "        #Inicia índices\n",
    "        idx = 0\n",
    "        for filename in glob(directory+'*'):\n",
    "            #Lee los archivos en el directorio\n",
    "            text = open(filename,'r').read()\n",
    "            #Tokeniza documentos\n",
    "            tokenized_text = tokenize(text)\n",
    "            #Guarda los índices\n",
    "            self.docs_idx[idx] = filename\n",
    "            #Crea la colección\n",
    "            self.collection[idx] = list(sorted(set(tokenized_text)))\n",
    "            #Avanza en el índice\n",
    "            idx += 1\n",
    "            \n",
    "        #Crea la lsita de términos\n",
    "        self.terms = list(set(chain(*self.collection.values())))\n",
    "        #Crea lista de documentos\n",
    "        self.documents = list(self.docs_idx.values())\n",
    "        \n",
    "    def build_incidence_matrix(self, directory):\n",
    "        \"\"\"\n",
    "        Función para la creación de la matriz de incidencia.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        directory : str\n",
    "            Directorio donde se encuentran guardados los documentos\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "            Matriz de incidencia\n",
    "        \"\"\"\n",
    "        #Crea la colección a partir de directorio\n",
    "        self.get_documents(directory)\n",
    "        #Inicializa la matriz de incidencia con 0s\n",
    "        self.incidence_matrix = np.zeros((len(self.terms),len(self.collection)))\n",
    "        \n",
    "        #Recorre los términos y los documentos\n",
    "        for i,t in enumerate(self.terms):\n",
    "            for j,(d, terms_doc) in enumerate(self.collection.items()):\n",
    "                #Si el término está en documento agrega 1.\n",
    "                if t in terms_doc:\n",
    "                    self.incidence_matrix[i,j] = 1\n",
    "\n",
    "    def vectorize(self, term):\n",
    "        \"\"\"\n",
    "        Función para crear un vector booleano de un término-\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        term : str\n",
    "            Término que se va a representar\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        vector : array\n",
    "            Vector booleano obtenido de los renglones de matriz de incidencia.\n",
    "        \"\"\"\n",
    "        #Obtiene el índice del término\n",
    "        term_idx = self.terms.index(term)\n",
    "        #Recupera el renglón de la matriz a partir del índice\n",
    "        vector = self.incidence_matrix[term_idx]\n",
    "        \n",
    "        return vector\n",
    "    \n",
    "    def searchAND(self,term1,term2):\n",
    "        \"\"\"\n",
    "        Aplica el operador AND entre dos términos con respecto a sus vectores booleanos.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        term1, term2 : str\n",
    "            Términos que se van a operar.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Documentos que responden a la búsqueda AND entre los dos términos\n",
    "        \"\"\"\n",
    "        #Obtiene los vectores booleanos\n",
    "        vector1 = self.vectorize(term1)\n",
    "        vector2 = self.vectorize(term2)\n",
    "        \n",
    "        #Vector resultante\n",
    "        ANDVector = []\n",
    "        for i in range(len(self.documents)):\n",
    "            #Aplica el operador AND\n",
    "            ANDVector.append(AND(vector1[i], vector2[i]))\n",
    "        \n",
    "        #Recupera documentos que pertenecen\n",
    "        #a la búsqueda\n",
    "        for d,bit in enumerate(ANDVector):\n",
    "            if bit == 1:\n",
    "                yield self.documents[d]\n",
    "    \n",
    "    def searchOR(self,term1,term2):\n",
    "        \"\"\"\n",
    "        Aplica el operador OR entre dos términos con respecto a sus vectores booleanos.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        term1, term2 : str\n",
    "            Términos que se van a operar.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Documentos que responden a la búsqueda OR entre los dos términos\n",
    "        \"\"\"\n",
    "        #Obtiene los vectores booleanos de los términos\n",
    "        vector1 = self.vectorize(term1)\n",
    "        vector2 = self.vectorize(term2)\n",
    "        \n",
    "        #Vector resultante\n",
    "        ORVector = []\n",
    "        for i in range(len(self.documents)):\n",
    "            #Aplica operación OR\n",
    "            ORVector.append(OR(vector1[i], vector2[i]))\n",
    "        \n",
    "        #Recupera documentos que pertenecen\n",
    "        #a la búsqueda\n",
    "        for d,bit in enumerate(ORVector):\n",
    "            if bit == 1:\n",
    "                yield self.documents[d]\n",
    "    \n",
    "    def searchNOT(self,term):\n",
    "        \"\"\"\n",
    "        Aplica el operador NOT a un términos con respecto a su vector booleano.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        term1 : str\n",
    "            Término que se va a operar.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Documentos que responden a la búsqueda NOT del término\n",
    "        \"\"\"\n",
    "        #Obtiene vector booleano\n",
    "        vector = self.vectorize(term)\n",
    "        \n",
    "        #Vector resultante\n",
    "        NOTVector = []\n",
    "        for i in range(len(self.documents)):\n",
    "            #Aplica operación NOT\n",
    "            NOTVector.append(NOT(vector[i]))\n",
    "        \n",
    "        #Recupera documentos que pertenecen\n",
    "        #a la búsqueda\n",
    "        for d,bit in enumerate(NOTVector):\n",
    "            if bit == 1:\n",
    "                yield self.documents[d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e635c",
   "metadata": {},
   "source": [
    "Podemos, entonces probar el modelo de búsqueda booleana creando la matriz de incidencia, así como las listas de términos y de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1de567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Términos: ['inmigran', 'glándula', 'engañosos', 'cambió', 'autónomo', 'diferenciarse', 'lakatos', 'nanotube', 'amigo', 'tocaba']\n",
      "Documentos: ['wikipedia/cuantica (2).txt', 'wikipedia/fractal (1).txt', 'wikipedia/bioinfo (1).txt', 'wikipedia/ifai (4).txt', 'wikipedia/taylor (1).txt']\n"
     ]
    }
   ],
   "source": [
    "#Directorio de documentos\n",
    "directory = 'wikipedia/'\n",
    "\n",
    "#Creamos modelo de búsqueda booleana\n",
    "model = BooleanRetrieval()\n",
    "#Construimos la matriz de incidencia\n",
    "model.build_incidence_matrix(directory)\n",
    "\n",
    "print(model.incidence_matrix)\n",
    "print(\"Términos: {}\\nDocumentos: {}\".format(model.terms[:10], model.documents[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f5541",
   "metadata": {},
   "source": [
    "Usaremos pandas para visualizar mejor la matriz de incidencia y poder ver las relaciones entre los términos y los documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f489b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia/cuantica (2).txt</th>\n",
       "      <th>wikipedia/fractal (1).txt</th>\n",
       "      <th>wikipedia/bioinfo (1).txt</th>\n",
       "      <th>wikipedia/ifai (4).txt</th>\n",
       "      <th>wikipedia/taylor (1).txt</th>\n",
       "      <th>wikipedia/ciencia_historia (1).txt</th>\n",
       "      <th>wikipedia/ech (1).txt</th>\n",
       "      <th>wikipedia/religion (1).txt</th>\n",
       "      <th>wikipedia/perro (1).txt</th>\n",
       "      <th>wikipedia/cine (2).txt</th>\n",
       "      <th>...</th>\n",
       "      <th>wikipedia/cuantica (3).txt</th>\n",
       "      <th>wikipedia/economia (2).txt</th>\n",
       "      <th>wikipedia/bioinfo (2).txt</th>\n",
       "      <th>wikipedia/ciencia_historia (3).txt</th>\n",
       "      <th>wikipedia/acustica (3).txt</th>\n",
       "      <th>wikipedia/sushi (2).txt</th>\n",
       "      <th>wikipedia/coca (2).txt</th>\n",
       "      <th>wikipedia/celula (7).txt</th>\n",
       "      <th>wikipedia/twitter (2).txt</th>\n",
       "      <th>wikipedia/condensador (3).txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inmigran</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glándula</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engañosos</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cambió</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autónomo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o26h11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deberá</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>µf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15731 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           wikipedia/cuantica (2).txt  wikipedia/fractal (1).txt  \\\n",
       "inmigran                          0.0                        0.0   \n",
       "glándula                          0.0                        0.0   \n",
       "engañosos                         0.0                        0.0   \n",
       "cambió                            0.0                        0.0   \n",
       "autónomo                          0.0                        0.0   \n",
       "...                               ...                        ...   \n",
       "co                                0.0                        0.0   \n",
       "o26h11                            0.0                        0.0   \n",
       "av                                0.0                        0.0   \n",
       "deberá                            0.0                        0.0   \n",
       "µf                                0.0                        0.0   \n",
       "\n",
       "           wikipedia/bioinfo (1).txt  wikipedia/ifai (4).txt  \\\n",
       "inmigran                         0.0                     0.0   \n",
       "glándula                         0.0                     0.0   \n",
       "engañosos                        0.0                     0.0   \n",
       "cambió                           0.0                     0.0   \n",
       "autónomo                         0.0                     0.0   \n",
       "...                              ...                     ...   \n",
       "co                               0.0                     0.0   \n",
       "o26h11                           0.0                     0.0   \n",
       "av                               0.0                     0.0   \n",
       "deberá                           0.0                     0.0   \n",
       "µf                               0.0                     0.0   \n",
       "\n",
       "           wikipedia/taylor (1).txt  wikipedia/ciencia_historia (1).txt  \\\n",
       "inmigran                        0.0                                 0.0   \n",
       "glándula                        0.0                                 0.0   \n",
       "engañosos                       0.0                                 0.0   \n",
       "cambió                          0.0                                 1.0   \n",
       "autónomo                        0.0                                 0.0   \n",
       "...                             ...                                 ...   \n",
       "co                              0.0                                 0.0   \n",
       "o26h11                          0.0                                 0.0   \n",
       "av                              0.0                                 0.0   \n",
       "deberá                          0.0                                 0.0   \n",
       "µf                              0.0                                 0.0   \n",
       "\n",
       "           wikipedia/ech (1).txt  wikipedia/religion (1).txt  \\\n",
       "inmigran                     0.0                         0.0   \n",
       "glándula                     0.0                         0.0   \n",
       "engañosos                    0.0                         0.0   \n",
       "cambió                       0.0                         0.0   \n",
       "autónomo                     0.0                         0.0   \n",
       "...                          ...                         ...   \n",
       "co                           0.0                         0.0   \n",
       "o26h11                       0.0                         0.0   \n",
       "av                           0.0                         0.0   \n",
       "deberá                       0.0                         0.0   \n",
       "µf                           0.0                         0.0   \n",
       "\n",
       "           wikipedia/perro (1).txt  wikipedia/cine (2).txt  ...  \\\n",
       "inmigran                       0.0                     0.0  ...   \n",
       "glándula                       0.0                     0.0  ...   \n",
       "engañosos                      0.0                     0.0  ...   \n",
       "cambió                         0.0                     0.0  ...   \n",
       "autónomo                       0.0                     0.0  ...   \n",
       "...                            ...                     ...  ...   \n",
       "co                             0.0                     0.0  ...   \n",
       "o26h11                         0.0                     0.0  ...   \n",
       "av                             0.0                     0.0  ...   \n",
       "deberá                         0.0                     0.0  ...   \n",
       "µf                             0.0                     0.0  ...   \n",
       "\n",
       "           wikipedia/cuantica (3).txt  wikipedia/economia (2).txt  \\\n",
       "inmigran                          0.0                         0.0   \n",
       "glándula                          0.0                         0.0   \n",
       "engañosos                         0.0                         0.0   \n",
       "cambió                            0.0                         0.0   \n",
       "autónomo                          0.0                         0.0   \n",
       "...                               ...                         ...   \n",
       "co                                0.0                         0.0   \n",
       "o26h11                            0.0                         0.0   \n",
       "av                                0.0                         0.0   \n",
       "deberá                            0.0                         0.0   \n",
       "µf                                0.0                         0.0   \n",
       "\n",
       "           wikipedia/bioinfo (2).txt  wikipedia/ciencia_historia (3).txt  \\\n",
       "inmigran                         0.0                                 0.0   \n",
       "glándula                         0.0                                 0.0   \n",
       "engañosos                        0.0                                 1.0   \n",
       "cambió                           0.0                                 0.0   \n",
       "autónomo                         0.0                                 0.0   \n",
       "...                              ...                                 ...   \n",
       "co                               0.0                                 0.0   \n",
       "o26h11                           0.0                                 0.0   \n",
       "av                               0.0                                 0.0   \n",
       "deberá                           0.0                                 0.0   \n",
       "µf                               0.0                                 0.0   \n",
       "\n",
       "           wikipedia/acustica (3).txt  wikipedia/sushi (2).txt  \\\n",
       "inmigran                          0.0                      0.0   \n",
       "glándula                          0.0                      0.0   \n",
       "engañosos                         0.0                      0.0   \n",
       "cambió                            0.0                      0.0   \n",
       "autónomo                          0.0                      0.0   \n",
       "...                               ...                      ...   \n",
       "co                                0.0                      0.0   \n",
       "o26h11                            0.0                      0.0   \n",
       "av                                0.0                      0.0   \n",
       "deberá                            0.0                      0.0   \n",
       "µf                                0.0                      0.0   \n",
       "\n",
       "           wikipedia/coca (2).txt  wikipedia/celula (7).txt  \\\n",
       "inmigran                      0.0                       0.0   \n",
       "glándula                      0.0                       0.0   \n",
       "engañosos                     0.0                       0.0   \n",
       "cambió                        0.0                       0.0   \n",
       "autónomo                      1.0                       0.0   \n",
       "...                           ...                       ...   \n",
       "co                            0.0                       0.0   \n",
       "o26h11                        0.0                       0.0   \n",
       "av                            0.0                       0.0   \n",
       "deberá                        0.0                       0.0   \n",
       "µf                            0.0                       0.0   \n",
       "\n",
       "           wikipedia/twitter (2).txt  wikipedia/condensador (3).txt  \n",
       "inmigran                         0.0                            0.0  \n",
       "glándula                         0.0                            0.0  \n",
       "engañosos                        0.0                            0.0  \n",
       "cambió                           0.0                            0.0  \n",
       "autónomo                         0.0                            0.0  \n",
       "...                              ...                            ...  \n",
       "co                               0.0                            0.0  \n",
       "o26h11                           0.0                            0.0  \n",
       "av                               0.0                            0.0  \n",
       "deberá                           0.0                            0.0  \n",
       "µf                               0.0                            1.0  \n",
       "\n",
       "[15731 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualización de la matriz de incidencia con PANDAS\n",
    "IncidenceMatrix = pd.DataFrame(data=model.incidence_matrix,index=model.terms,columns=model.documents)\n",
    "IncidenceMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe52bc64",
   "metadata": {},
   "source": [
    "También pandas nos permite localizar los renglones que representan los términos a partir de .loc[]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893b83f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia/cuantica (2).txt</th>\n",
       "      <th>wikipedia/fractal (1).txt</th>\n",
       "      <th>wikipedia/bioinfo (1).txt</th>\n",
       "      <th>wikipedia/ifai (4).txt</th>\n",
       "      <th>wikipedia/taylor (1).txt</th>\n",
       "      <th>wikipedia/ciencia_historia (1).txt</th>\n",
       "      <th>wikipedia/ech (1).txt</th>\n",
       "      <th>wikipedia/religion (1).txt</th>\n",
       "      <th>wikipedia/perro (1).txt</th>\n",
       "      <th>wikipedia/cine (2).txt</th>\n",
       "      <th>...</th>\n",
       "      <th>wikipedia/cuantica (3).txt</th>\n",
       "      <th>wikipedia/economia (2).txt</th>\n",
       "      <th>wikipedia/bioinfo (2).txt</th>\n",
       "      <th>wikipedia/ciencia_historia (3).txt</th>\n",
       "      <th>wikipedia/acustica (3).txt</th>\n",
       "      <th>wikipedia/sushi (2).txt</th>\n",
       "      <th>wikipedia/coca (2).txt</th>\n",
       "      <th>wikipedia/celula (7).txt</th>\n",
       "      <th>wikipedia/twitter (2).txt</th>\n",
       "      <th>wikipedia/condensador (3).txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>campo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campos</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wikipedia/cuantica (2).txt  wikipedia/fractal (1).txt  \\\n",
       "campo                          0.0                        0.0   \n",
       "campos                         1.0                        0.0   \n",
       "\n",
       "        wikipedia/bioinfo (1).txt  wikipedia/ifai (4).txt  \\\n",
       "campo                         1.0                     0.0   \n",
       "campos                        1.0                     0.0   \n",
       "\n",
       "        wikipedia/taylor (1).txt  wikipedia/ciencia_historia (1).txt  \\\n",
       "campo                        0.0                                 1.0   \n",
       "campos                       0.0                                 1.0   \n",
       "\n",
       "        wikipedia/ech (1).txt  wikipedia/religion (1).txt  \\\n",
       "campo                     0.0                         0.0   \n",
       "campos                    0.0                         0.0   \n",
       "\n",
       "        wikipedia/perro (1).txt  wikipedia/cine (2).txt  ...  \\\n",
       "campo                       0.0                     0.0  ...   \n",
       "campos                      0.0                     0.0  ...   \n",
       "\n",
       "        wikipedia/cuantica (3).txt  wikipedia/economia (2).txt  \\\n",
       "campo                          0.0                         1.0   \n",
       "campos                         1.0                         0.0   \n",
       "\n",
       "        wikipedia/bioinfo (2).txt  wikipedia/ciencia_historia (3).txt  \\\n",
       "campo                         1.0                                 0.0   \n",
       "campos                        0.0                                 0.0   \n",
       "\n",
       "        wikipedia/acustica (3).txt  wikipedia/sushi (2).txt  \\\n",
       "campo                          0.0                      0.0   \n",
       "campos                         0.0                      0.0   \n",
       "\n",
       "        wikipedia/coca (2).txt  wikipedia/celula (7).txt  \\\n",
       "campo                      0.0                       0.0   \n",
       "campos                     0.0                       0.0   \n",
       "\n",
       "        wikipedia/twitter (2).txt  wikipedia/condensador (3).txt  \n",
       "campo                         0.0                            1.0  \n",
       "campos                        0.0                            0.0  \n",
       "\n",
       "[2 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Búsqueda de términos y sus representaciones\n",
    "IncidenceMatrix.loc[['campo','campos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea483a",
   "metadata": {},
   "source": [
    "#### Recuperación de documentos por búsqueda booleana\n",
    "\n",
    "Finalmente podemos aplicar los distintos operadores para obtener los documentos que contienen la query booleana que solicitamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e32a1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia/bioinfo (1).txt\n",
      "wikipedia/ciencia_historia (1).txt\n",
      "wikipedia/mate (2).txt\n"
     ]
    }
   ],
   "source": [
    "#Recuperamos documentos a partir de operadores booleanos\n",
    "for result in model.searchAND('campo','campos'):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e89f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia/religion (2).txt\n",
      "wikipedia/sociedad (4).txt\n",
      "wikipedia/salmonella (2).txt\n",
      "wikipedia/pylori (1).txt\n"
     ]
    }
   ],
   "source": [
    "#uso del operador Not\n",
    "for result in model.searchNOT('un'):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e91e0",
   "metadata": {},
   "source": [
    "Este tipo de modelo permite hacer búsquedas más complejas que combinen diferentes operadores booleanos; por ejemplo, se pueden concatenar operaciones AND para recuperar documentos que contengan más de dos términos. O bien operar con combinaciones de distintos operadores booleanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6248f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia/cuantica (2).txt\n",
      "wikipedia/mate (1).txt\n",
      "wikipedia/sociedad (2).txt\n",
      "wikipedia/condensador (2).txt\n",
      "wikipedia/politica (1).txt\n",
      "wikipedia/capoeira (2).txt\n",
      "wikipedia/cuantica (1).txt\n",
      "wikipedia/condensador (4).txt\n",
      "wikipedia/ifai (2).txt\n",
      "wikipedia/sociedad (1).txt\n",
      "wikipedia/economia (1).txt\n",
      "wikipedia/cuantica (3).txt\n",
      "wikipedia/economia (2).txt\n",
      "wikipedia/bioinfo (2).txt\n",
      "wikipedia/condensador (3).txt\n"
     ]
    }
   ],
   "source": [
    "#Vectoriza dos modelos\n",
    "u = model.vectorize('campo')\n",
    "v = model.vectorize('campos')\n",
    "\n",
    "#Operador OR EXclusivo\n",
    "XOR = lambda x,y: AND(NOT(AND(x,y)), OR(x,y))\n",
    "\n",
    "#Búsqueda compleja\n",
    "result = [XOR(u[i],v[i]) for i in range(len(u))]\n",
    "\n",
    "#Recupera documentos de búsqueda\n",
    "for d,bit in enumerate(result):\n",
    "    if bit == 1:\n",
    "        print(model.documents[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91641f45",
   "metadata": {},
   "source": [
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
